{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "227b3994",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "This notebook loads Athena-preprocessed AAL ROI time series from the ADHD-200 dataset,\n",
    "validates their structure, and builds a clean subject-level index by matching\n",
    "time series files with phenotypic labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34573791",
   "metadata": {},
   "source": [
    "## Notebook scope\n",
    "\n",
    "**Goal**  \n",
    "This notebook constructs the subject-level dataset used for the replication study by:\n",
    "- loading Athena-preprocessed AAL ROI time series,\n",
    "- validating and cleaning the data format,\n",
    "- matching subjects with phenotypic labels,\n",
    "- applying the same site-selection criteria as the original paper,\n",
    "- exporting reproducible subject manifests for downstream experiments.\n",
    "\n",
    "**Out of scope**  \n",
    "This notebook does **not** perform raw rs-fMRI preprocessing (slice timing correction, motion correction, filtering, nuisance regression, etc.), as these steps are already applied in the Athena preprocessing pipeline.\n",
    "\n",
    "**Outputs**\n",
    "- `data/processed/subjects_train.csv` – all labeled subjects with available AAL time series  \n",
    "- `data/processed/subjects_train_paper.csv` – subset restricted to sites used in the original paper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f20c1f",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "58d25ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT: /Users/mariaborca/Documents/AI_2023-2026/Semestrul_5/KBS/Report_3/adhd-tcn-replication\n",
      "AAL_ROOT exists: True -> /Users/mariaborca/Documents/AI_2023-2026/Semestrul_5/KBS/Report_3/adhd-tcn-replication/data/raw/aal_tcs\n",
      "PHENO_ROOT exists: True -> /Users/mariaborca/Documents/AI_2023-2026/Semestrul_5/KBS/Report_3/adhd-tcn-replication/data/raw/phenotypic\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "PROJECT_ROOT = Path(\"..\").resolve()\n",
    "DATA_RAW = PROJECT_ROOT / \"data\" / \"raw\"\n",
    "DATA_PROCESSED = PROJECT_ROOT / \"data\" / \"processed\"\n",
    "\n",
    "AAL_ROOT = DATA_RAW / \"aal_tcs\"\n",
    "PHENO_ROOT = DATA_RAW / \"phenotypic\"\n",
    "\n",
    "DATA_PROCESSED.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"AAL_ROOT exists:\", AAL_ROOT.exists(), \"->\", AAL_ROOT)\n",
    "print(\"PHENO_ROOT exists:\", PHENO_ROOT.exists(), \"->\", PHENO_ROOT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba038c14",
   "metadata": {},
   "source": [
    "## Data inputs\n",
    "\n",
    "This notebook expects the following directory structure:\n",
    "\n",
    "- **AAL ROI time series (Athena preprocessed)**  \n",
    "  `data/raw/aal_tcs/<Site>/<SubjectID>/*.1D`\n",
    "\n",
    "- **Phenotypic labels**  \n",
    "  `data/raw/phenotypic/<Site>/*_phenotypic.csv`\n",
    "\n",
    "Only Athena-derived AAL time courses with corrected filtering (`sfnwmrda*_aal_TCs.1D`) are used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0637d0",
   "metadata": {},
   "source": [
    "## 2. Find the filtered AAL time-course files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10fb9f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered AAL files found: 1395\n",
      "Example:\n",
      "   /Users/mariaborca/Documents/AI_2023-2026/Semestrul_5/KBS/Report_3/adhd-tcn-replication/data/raw/aal_tcs/Brown/0026001/sfnwmrda0026001_session_1_rest_1_aal_TCs.1D\n",
      "   /Users/mariaborca/Documents/AI_2023-2026/Semestrul_5/KBS/Report_3/adhd-tcn-replication/data/raw/aal_tcs/Brown/0026002/sfnwmrda0026002_session_1_rest_1_aal_TCs.1D\n",
      "   /Users/mariaborca/Documents/AI_2023-2026/Semestrul_5/KBS/Report_3/adhd-tcn-replication/data/raw/aal_tcs/Brown/0026004/sfnwmrda0026004_session_1_rest_1_aal_TCs.1D\n",
      "   /Users/mariaborca/Documents/AI_2023-2026/Semestrul_5/KBS/Report_3/adhd-tcn-replication/data/raw/aal_tcs/Brown/0026005/sfnwmrda0026005_session_1_rest_1_aal_TCs.1D\n",
      "   /Users/mariaborca/Documents/AI_2023-2026/Semestrul_5/KBS/Report_3/adhd-tcn-replication/data/raw/aal_tcs/Brown/0026009/sfnwmrda0026009_session_1_rest_1_aal_TCs.1D\n"
     ]
    }
   ],
   "source": [
    "aal_files = sorted(AAL_ROOT.rglob(\"sfnwmrda*_aal_TCs.1D\"))\n",
    "\n",
    "print(\"Filtered AAL files found:\", len(aal_files))\n",
    "print(\"Example:\")\n",
    "for p in aal_files[:5]:\n",
    "    print(\"  \", p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74042486",
   "metadata": {},
   "source": [
    "## AAL time-course file format\n",
    "\n",
    "Each `.1D` file contains a tab-separated table with:\n",
    "\n",
    "- **Rows**: time points (sub-bricks / TRs)\n",
    "- **Columns**:\n",
    "  - Metadata columns: `File`, `Sub-brick`\n",
    "  - ROI signal columns: `Mean_XXXX` (116 regions from the AAL atlas)\n",
    "\n",
    "In this notebook:\n",
    "- Only the 116 ROI columns are retained.\n",
    "- Metadata columns are discarded.\n",
    "- The resulting data matrix has shape **(T, 116)** per subject."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c03c5c",
   "metadata": {},
   "source": [
    "## 3. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3786108d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_athena_aal_1d(path: Path, expect_rois: int = 116):\n",
    "    \"\"\"\n",
    "    Loads Athena AAL time courses from .1D with a header.\n",
    "    Keeps only ROI columns (Mean_...) and returns X with shape (T, R).\n",
    "    \"\"\"\n",
    "    # Header line is tab-separated\n",
    "    with open(path, \"r\") as f:\n",
    "        header = f.readline().strip().split(\"\\t\")\n",
    "\n",
    "    roi_cols = [i for i, name in enumerate(header) if name.startswith(\"Mean_\")]\n",
    "    if len(roi_cols) != expect_rois:\n",
    "        print(f\"[WARN] {path.name}: found {len(roi_cols)} ROI columns (expected {expect_rois})\")\n",
    "\n",
    "    # Load as strings then slice ROI columns\n",
    "    raw = np.genfromtxt(path, delimiter=\"\\t\", skip_header=1, dtype=str)\n",
    "    raw = np.atleast_2d(raw)  # safety\n",
    "\n",
    "    X = raw[:, roi_cols].astype(float)\n",
    "\n",
    "    # Fill NaNs safely\n",
    "    if np.isnan(X).any():\n",
    "        col_means = np.nanmean(X, axis=0)\n",
    "        col_means = np.where(np.isnan(col_means), 0.0, col_means)\n",
    "        inds = np.where(np.isnan(X))\n",
    "        X[inds] = np.take(col_means, inds[1])\n",
    "\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "67096dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brown 0026001 sfnwmrda0026001_session_1_rest_1_aal_TCs.1D -> (247, 116) NaNs: 0\n",
      "Brown 0026002 sfnwmrda0026002_session_1_rest_1_aal_TCs.1D -> (247, 116) NaNs: 0\n",
      "Brown 0026004 sfnwmrda0026004_session_1_rest_1_aal_TCs.1D -> (247, 116) NaNs: 0\n"
     ]
    }
   ],
   "source": [
    "for p in aal_files[:3]:\n",
    "    X = load_athena_aal_1d(p)\n",
    "    print(p.parts[-3], p.parts[-2], p.name, \"->\", X.shape, \"NaNs:\", np.isnan(X).sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7e4e6b",
   "metadata": {},
   "source": [
    "## Step: Build time-course manifest\n",
    "\n",
    "We construct a subject-level manifest (`df_tc`) containing:\n",
    "- site identifier,\n",
    "- subject ID,\n",
    "- path to the AAL time-course file,\n",
    "- number of time points (T),\n",
    "- number of ROIs (R).\n",
    "\n",
    "This manifest enables deterministic merging with phenotypic labels and\n",
    "reproducible downstream feature extraction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5746e3bc",
   "metadata": {},
   "source": [
    "## 4. Build subject index table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b8770011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique subjects with time courses: 965\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "site",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "subject_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "tc_path",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "T",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "R",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "bb43d55d-91d3-43fe-b328-8f075dedb856",
       "rows": [
        [
         "120",
         "NYU",
         "0010001",
         "/Users/mariaborca/Documents/AI_2023-2026/Semestrul_5/KBS/Report_3/adhd-tcn-replication/data/raw/aal_tcs/NYU/0010001/sfnwmrda0010001_session_1_rest_1_aal_TCs.1D",
         "172",
         "116"
        ],
        [
         "122",
         "NYU",
         "0010002",
         "/Users/mariaborca/Documents/AI_2023-2026/Semestrul_5/KBS/Report_3/adhd-tcn-replication/data/raw/aal_tcs/NYU/0010002/sfnwmrda0010002_session_1_rest_1_aal_TCs.1D",
         "172",
         "116"
        ],
        [
         "124",
         "NYU",
         "0010003",
         "/Users/mariaborca/Documents/AI_2023-2026/Semestrul_5/KBS/Report_3/adhd-tcn-replication/data/raw/aal_tcs/NYU/0010003/sfnwmrda0010003_session_1_rest_1_aal_TCs.1D",
         "172",
         "116"
        ],
        [
         "125",
         "NYU",
         "0010004",
         "/Users/mariaborca/Documents/AI_2023-2026/Semestrul_5/KBS/Report_3/adhd-tcn-replication/data/raw/aal_tcs/NYU/0010004/sfnwmrda0010004_session_1_rest_1_aal_TCs.1D",
         "172",
         "116"
        ],
        [
         "127",
         "NYU",
         "0010005",
         "/Users/mariaborca/Documents/AI_2023-2026/Semestrul_5/KBS/Report_3/adhd-tcn-replication/data/raw/aal_tcs/NYU/0010005/sfnwmrda0010005_session_1_rest_1_aal_TCs.1D",
         "172",
         "116"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>tc_path</th>\n",
       "      <th>T</th>\n",
       "      <th>R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>NYU</td>\n",
       "      <td>0010001</td>\n",
       "      <td>/Users/mariaborca/Documents/AI_2023-2026/Semes...</td>\n",
       "      <td>172</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>NYU</td>\n",
       "      <td>0010002</td>\n",
       "      <td>/Users/mariaborca/Documents/AI_2023-2026/Semes...</td>\n",
       "      <td>172</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>NYU</td>\n",
       "      <td>0010003</td>\n",
       "      <td>/Users/mariaborca/Documents/AI_2023-2026/Semes...</td>\n",
       "      <td>172</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>NYU</td>\n",
       "      <td>0010004</td>\n",
       "      <td>/Users/mariaborca/Documents/AI_2023-2026/Semes...</td>\n",
       "      <td>172</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>NYU</td>\n",
       "      <td>0010005</td>\n",
       "      <td>/Users/mariaborca/Documents/AI_2023-2026/Semes...</td>\n",
       "      <td>172</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    site subject_id                                            tc_path    T  \\\n",
       "120  NYU    0010001  /Users/mariaborca/Documents/AI_2023-2026/Semes...  172   \n",
       "122  NYU    0010002  /Users/mariaborca/Documents/AI_2023-2026/Semes...  172   \n",
       "124  NYU    0010003  /Users/mariaborca/Documents/AI_2023-2026/Semes...  172   \n",
       "125  NYU    0010004  /Users/mariaborca/Documents/AI_2023-2026/Semes...  172   \n",
       "127  NYU    0010005  /Users/mariaborca/Documents/AI_2023-2026/Semes...  172   \n",
       "\n",
       "       R  \n",
       "120  116  \n",
       "122  116  \n",
       "124  116  \n",
       "125  116  \n",
       "127  116  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_site_subject(p: Path):\n",
    "    # data/raw/aal_tcs/<SITE>/<SUBJECT>/<FILE>\n",
    "    parts = p.parts\n",
    "    site = parts[parts.index(\"aal_tcs\") + 1]\n",
    "    subject_id = parts[parts.index(\"aal_tcs\") + 2]\n",
    "    return site, subject_id\n",
    "\n",
    "rows = []\n",
    "for p in aal_files:\n",
    "    site, subject_id = parse_site_subject(p)\n",
    "    X = load_athena_aal_1d(p)\n",
    "    rows.append({\n",
    "        \"site\": site,\n",
    "        \"subject_id\": subject_id,\n",
    "        \"tc_path\": str(p),\n",
    "        \"T\": int(X.shape[0]),\n",
    "        \"R\": int(X.shape[1]),\n",
    "    })\n",
    "\n",
    "df_tc = pd.DataFrame(rows)\n",
    "\n",
    "# If duplicates exist per subject, keep the first (should be rare with sfnwmrda)\n",
    "df_tc = df_tc.sort_values([\"subject_id\", \"tc_path\"]).drop_duplicates(\"subject_id\")\n",
    "\n",
    "print(\"Unique subjects with time courses:\", len(df_tc))\n",
    "df_tc.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51291a29",
   "metadata": {},
   "source": [
    "## Step: Load phenotypic labels\n",
    "\n",
    "Phenotypic data are loaded from site-specific CSV files.\n",
    "Only training phenotypic files are used (TestRelease files are excluded).\n",
    "Diagnostic labels are extracted from the `DX` column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b6e289",
   "metadata": {},
   "source": [
    "## 5. Load and combine training phenotypics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7623fe7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phenotypic CSVs (training): 9\n",
      "  data/raw/phenotypic/KKI/KKI_phenotypic.csv\n",
      "  data/raw/phenotypic/NYU/NYU_phenotypic.csv\n",
      "  data/raw/phenotypic/NeuroIMAGE/NeuroIMAGE_phenotypic.csv\n",
      "  data/raw/phenotypic/OHSU/OHSU_phenotypic.csv\n",
      "  data/raw/phenotypic/Peking_1/Peking_1_phenotypic.csv\n",
      "  data/raw/phenotypic/Peking_2/Peking_2_phenotypic.csv\n",
      "  data/raw/phenotypic/Peking_3/Peking_3_phenotypic.csv\n",
      "  data/raw/phenotypic/Pittsburgh/Pittsburgh_phenotypic.csv\n",
      "  data/raw/phenotypic/WashU/WashU_phenotypic.csv\n"
     ]
    }
   ],
   "source": [
    "# Training phenotypics (exclude TestRelease files)\n",
    "pheno_files = sorted([\n",
    "    p for p in PHENO_ROOT.rglob(\"*_phenotypic.csv\")\n",
    "    if \"TestRelease\" not in p.name\n",
    "])\n",
    "\n",
    "print(\"Phenotypic CSVs (training):\", len(pheno_files))\n",
    "for p in pheno_files:\n",
    "    print(\" \", p.relative_to(PROJECT_ROOT))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "52349ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined phenotypic rows: 776\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ScanDir ID",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Site",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Gender",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Age",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Handedness",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "DX",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Secondary Dx",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "ADHD Measure",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ADHD Index",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Inattentive",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Hyper/Impulsive",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "IQ Measure",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Verbal IQ",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Performance IQ",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Full2 IQ",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Full4 IQ",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Med Status",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "QC_Rest_1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "QC_Rest_2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "QC_Rest_3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "QC_Rest_4",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "QC_Anatomical_1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "QC_Anatomical_2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "site",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "ScanDirID",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Study #",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "QC_S1_Rest_1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "QC_S1_Rest_2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "QC_S1_Rest_3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "QC_S1_Rest_4",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "QC_S1_Rest_5",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "QC_S1_Rest_6",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "QC_S1_Anat",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "QC_S2_Rest_1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "QC_S2_Rest_2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "QC_S2_Anat",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "4adcbe44-c931-43be-add0-8ff2a4357fd5",
       "rows": [
        [
         "0",
         "1018959.0",
         "3",
         "0.0",
         "12.36",
         "1.0",
         "0",
         null,
         "2.0",
         "44.0",
         "47.0",
         "44.0",
         "1.0",
         "99.0",
         "115.0",
         null,
         "103.0",
         "1.0",
         "1.0",
         null,
         null,
         null,
         "1.0",
         null,
         "KKI",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "1",
         "1019436.0",
         "3",
         "1.0",
         "12.98",
         "1.0",
         "3",
         null,
         "2.0",
         "71.0",
         "60.0",
         "66.0",
         "1.0",
         "124.0",
         "108.0",
         null,
         "122.0",
         "1.0",
         "1.0",
         null,
         null,
         null,
         "1.0",
         null,
         "KKI",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "2",
         "1043241.0",
         "3",
         "1.0",
         "9.12",
         "1.0",
         "0",
         null,
         "2.0",
         "40.0",
         "40.0",
         "43.0",
         "1.0",
         "128.0",
         "106.0",
         null,
         "120.0",
         "1.0",
         "1.0",
         null,
         null,
         null,
         "1.0",
         null,
         "KKI",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "3",
         "1266183.0",
         "3",
         "0.0",
         "9.67",
         "1.0",
         "0",
         null,
         "2.0",
         "47.0",
         "44.0",
         "43.0",
         "1.0",
         "136.0",
         "96.0",
         null,
         "120.0",
         "1.0",
         "1.0",
         null,
         null,
         null,
         "1.0",
         null,
         "KKI",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "4",
         "1535233.0",
         "3",
         "1.0",
         "9.64",
         "0.0",
         "0",
         null,
         "2.0",
         "42.0",
         "41.0",
         "43.0",
         "1.0",
         "106.0",
         "135.0",
         null,
         "122.0",
         "1.0",
         "1.0",
         null,
         null,
         null,
         "1.0",
         null,
         "KKI",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ]
       ],
       "shape": {
        "columns": 36,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ScanDir ID</th>\n",
       "      <th>Site</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Handedness</th>\n",
       "      <th>DX</th>\n",
       "      <th>Secondary Dx</th>\n",
       "      <th>ADHD Measure</th>\n",
       "      <th>ADHD Index</th>\n",
       "      <th>Inattentive</th>\n",
       "      <th>...</th>\n",
       "      <th>QC_S1_Rest_1</th>\n",
       "      <th>QC_S1_Rest_2</th>\n",
       "      <th>QC_S1_Rest_3</th>\n",
       "      <th>QC_S1_Rest_4</th>\n",
       "      <th>QC_S1_Rest_5</th>\n",
       "      <th>QC_S1_Rest_6</th>\n",
       "      <th>QC_S1_Anat</th>\n",
       "      <th>QC_S2_Rest_1</th>\n",
       "      <th>QC_S2_Rest_2</th>\n",
       "      <th>QC_S2_Anat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1018959.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1019436.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.98</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1043241.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1266183.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.67</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1535233.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ScanDir ID  Site  Gender    Age  Handedness  DX Secondary Dx  ADHD Measure  \\\n",
       "0   1018959.0     3     0.0  12.36         1.0   0          NaN           2.0   \n",
       "1   1019436.0     3     1.0  12.98         1.0   3          NaN           2.0   \n",
       "2   1043241.0     3     1.0   9.12         1.0   0          NaN           2.0   \n",
       "3   1266183.0     3     0.0   9.67         1.0   0          NaN           2.0   \n",
       "4   1535233.0     3     1.0   9.64         0.0   0          NaN           2.0   \n",
       "\n",
       "   ADHD Index  Inattentive  ...  QC_S1_Rest_1  QC_S1_Rest_2  QC_S1_Rest_3  \\\n",
       "0        44.0         47.0  ...           NaN           NaN           NaN   \n",
       "1        71.0         60.0  ...           NaN           NaN           NaN   \n",
       "2        40.0         40.0  ...           NaN           NaN           NaN   \n",
       "3        47.0         44.0  ...           NaN           NaN           NaN   \n",
       "4        42.0         41.0  ...           NaN           NaN           NaN   \n",
       "\n",
       "   QC_S1_Rest_4  QC_S1_Rest_5  QC_S1_Rest_6  QC_S1_Anat  QC_S2_Rest_1  \\\n",
       "0           NaN           NaN           NaN         NaN           NaN   \n",
       "1           NaN           NaN           NaN         NaN           NaN   \n",
       "2           NaN           NaN           NaN         NaN           NaN   \n",
       "3           NaN           NaN           NaN         NaN           NaN   \n",
       "4           NaN           NaN           NaN         NaN           NaN   \n",
       "\n",
       "   QC_S2_Rest_2  QC_S2_Anat  \n",
       "0           NaN         NaN  \n",
       "1           NaN         NaN  \n",
       "2           NaN         NaN  \n",
       "3           NaN         NaN  \n",
       "4           NaN         NaN  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = []\n",
    "for p in pheno_files:\n",
    "    site = p.parent.name  # folder name is site\n",
    "    dfp = pd.read_csv(p)\n",
    "\n",
    "    # normalize column names\n",
    "    dfp.columns = [c.strip() for c in dfp.columns]\n",
    "\n",
    "    # attach site (to match df_tc.site)\n",
    "    dfp[\"site\"] = site\n",
    "    dfs.append(dfp)\n",
    "\n",
    "pheno = pd.concat(dfs, ignore_index=True)\n",
    "print(\"Combined phenotypic rows:\", len(pheno))\n",
    "pheno.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "016436cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phenotypic columns:\n",
      "['ADHD Index', 'ADHD Measure', 'Age', 'DX', 'Full2 IQ', 'Full4 IQ', 'Gender', 'Handedness', 'Hyper/Impulsive', 'IQ Measure', 'Inattentive', 'Med Status', 'Performance IQ', 'QC_Anatomical_1', 'QC_Anatomical_2', 'QC_Rest_1', 'QC_Rest_2', 'QC_Rest_3', 'QC_Rest_4', 'QC_S1_Anat', 'QC_S1_Rest_1', 'QC_S1_Rest_2', 'QC_S1_Rest_3', 'QC_S1_Rest_4', 'QC_S1_Rest_5', 'QC_S1_Rest_6', 'QC_S2_Anat', 'QC_S2_Rest_1', 'QC_S2_Rest_2', 'ScanDir ID', 'ScanDirID', 'Secondary Dx', 'Site', 'Study #', 'Verbal IQ', 'site']\n"
     ]
    }
   ],
   "source": [
    "print(\"Phenotypic columns:\")\n",
    "print(sorted(pheno.columns.tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5887135",
   "metadata": {},
   "source": [
    "## Subject ID normalization\n",
    "\n",
    "Subject identifiers appear in different formats across data sources.\n",
    "To ensure correct merging, all subject IDs are normalized to\n",
    "7-digit zero-padded strings before joining time-course and phenotypic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "32f3939b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example normalized IDs (pheno): ['1018959', '1019436', '1043241', '1266183', '1535233']\n",
      "Example normalized IDs (tc):    ['0010001', '0010002', '0010003', '0010004', '0010005']\n"
     ]
    }
   ],
   "source": [
    "# choose columns explicitly (based on your printout)\n",
    "subj_col = \"ScanDir ID\"\n",
    "dx_col = \"DX\"\n",
    "\n",
    "def norm_subject_id(x) -> str:\n",
    "    \"\"\"\n",
    "    Convert ScanDir ID to a 7-digit string with leading zeros if needed.\n",
    "    Handles floats like 1018959.0 safely.\n",
    "    \"\"\"\n",
    "    if pd.isna(x):\n",
    "        return None\n",
    "    # convert to int safely (drops .0)\n",
    "    xi = int(float(x))\n",
    "    return f\"{xi:07d}\"\n",
    "\n",
    "# Normalize phenotypic subject IDs\n",
    "pheno = pheno.copy()\n",
    "pheno[\"subject_id\"] = pheno[subj_col].apply(norm_subject_id)\n",
    "\n",
    "# Normalize df_tc subject IDs (folders already strings but ensure 7 digits)\n",
    "df_tc = df_tc.copy()\n",
    "df_tc[\"subject_id\"] = df_tc[\"subject_id\"].apply(lambda s: f\"{int(s):07d}\")\n",
    "\n",
    "print(\"Example normalized IDs (pheno):\", pheno[\"subject_id\"].dropna().head().tolist())\n",
    "print(\"Example normalized IDs (tc):   \", df_tc[\"subject_id\"].head().tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "79e840b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time-course subjects: 965\n",
      "Merged rows: 965\n",
      "Missing DX after merge: 256\n",
      "\n",
      "Missing DX by site:\n",
      " site\n",
      "WashU         59\n",
      "Peking_1      51\n",
      "NYU           41\n",
      "OHSU          34\n",
      "Brown         26\n",
      "NeuroIMAGE    25\n",
      "KKI           11\n",
      "Pittsburgh     9\n",
      "Name: subject_id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = df_tc.merge(\n",
    "    pheno[[\"site\", \"subject_id\", dx_col]],\n",
    "    on=[\"site\", \"subject_id\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "print(\"Time-course subjects:\", len(df_tc))\n",
    "print(\"Merged rows:\", len(df))\n",
    "print(\"Missing DX after merge:\", df[dx_col].isna().sum())\n",
    "\n",
    "# See which sites are missing most labels (useful debugging)\n",
    "missing_by_site = df[df[dx_col].isna()].groupby(\"site\")[\"subject_id\"].count().sort_values(ascending=False)\n",
    "print(\"\\nMissing DX by site:\\n\", missing_by_site.head(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73a89d3",
   "metadata": {},
   "source": [
    "## Label definition\n",
    "\n",
    "We formulate a binary classification task:\n",
    "- `DX == 0` → Control (label = 0)\n",
    "- `DX > 0` → ADHD (label = 1)\n",
    "\n",
    "All ADHD subtypes are collapsed into a single class, consistent with the original paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0cb7f7ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DX raw counts:\n",
      " dx_raw\n",
      "0.0    429\n",
      "1.0    159\n",
      "2.0     11\n",
      "3.0    110\n",
      "NaN    256\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Binary label counts:\n",
      " label\n",
      "0.0    429\n",
      "1.0    280\n",
      "NaN    256\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df[\"dx_raw\"] = pd.to_numeric(df[dx_col], errors=\"coerce\")\n",
    "\n",
    "# ADHD-200 convention: DX==0 is typically TDC; DX>0 ADHD (subtypes)\n",
    "df[\"label\"] = np.where(df[\"dx_raw\"].isna(), np.nan,\n",
    "                       np.where(df[\"dx_raw\"] == 0, 0, 1))\n",
    "\n",
    "print(\"DX raw counts:\\n\", df[\"dx_raw\"].value_counts(dropna=False).sort_index())\n",
    "print(\"\\nBinary label counts:\\n\", pd.Series(df[\"label\"]).value_counts(dropna=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f430bcc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /Users/mariaborca/Documents/AI_2023-2026/Semestrul_5/KBS/Report_3/adhd-tcn-replication/data/processed/subjects_train.csv\n",
      "Train subjects: 709\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "site",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "subject_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "tc_path",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "T",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "R",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "DX",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "dx_raw",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "label",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "245313e8-8eff-45b1-a319-452adb239285",
       "rows": [
        [
         "0",
         "NYU",
         "0010001",
         "/Users/mariaborca/Documents/AI_2023-2026/Semestrul_5/KBS/Report_3/adhd-tcn-replication/data/raw/aal_tcs/NYU/0010001/sfnwmrda0010001_session_1_rest_1_aal_TCs.1D",
         "172",
         "116",
         "3.0",
         "3.0",
         "1"
        ],
        [
         "1",
         "NYU",
         "0010002",
         "/Users/mariaborca/Documents/AI_2023-2026/Semestrul_5/KBS/Report_3/adhd-tcn-replication/data/raw/aal_tcs/NYU/0010002/sfnwmrda0010002_session_1_rest_1_aal_TCs.1D",
         "172",
         "116",
         "3.0",
         "3.0",
         "1"
        ],
        [
         "2",
         "NYU",
         "0010003",
         "/Users/mariaborca/Documents/AI_2023-2026/Semestrul_5/KBS/Report_3/adhd-tcn-replication/data/raw/aal_tcs/NYU/0010003/sfnwmrda0010003_session_1_rest_1_aal_TCs.1D",
         "172",
         "116",
         "0.0",
         "0.0",
         "0"
        ],
        [
         "3",
         "NYU",
         "0010004",
         "/Users/mariaborca/Documents/AI_2023-2026/Semestrul_5/KBS/Report_3/adhd-tcn-replication/data/raw/aal_tcs/NYU/0010004/sfnwmrda0010004_session_1_rest_1_aal_TCs.1D",
         "172",
         "116",
         "0.0",
         "0.0",
         "0"
        ],
        [
         "4",
         "NYU",
         "0010005",
         "/Users/mariaborca/Documents/AI_2023-2026/Semestrul_5/KBS/Report_3/adhd-tcn-replication/data/raw/aal_tcs/NYU/0010005/sfnwmrda0010005_session_1_rest_1_aal_TCs.1D",
         "172",
         "116",
         "2.0",
         "2.0",
         "1"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>tc_path</th>\n",
       "      <th>T</th>\n",
       "      <th>R</th>\n",
       "      <th>DX</th>\n",
       "      <th>dx_raw</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NYU</td>\n",
       "      <td>0010001</td>\n",
       "      <td>/Users/mariaborca/Documents/AI_2023-2026/Semes...</td>\n",
       "      <td>172</td>\n",
       "      <td>116</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NYU</td>\n",
       "      <td>0010002</td>\n",
       "      <td>/Users/mariaborca/Documents/AI_2023-2026/Semes...</td>\n",
       "      <td>172</td>\n",
       "      <td>116</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NYU</td>\n",
       "      <td>0010003</td>\n",
       "      <td>/Users/mariaborca/Documents/AI_2023-2026/Semes...</td>\n",
       "      <td>172</td>\n",
       "      <td>116</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NYU</td>\n",
       "      <td>0010004</td>\n",
       "      <td>/Users/mariaborca/Documents/AI_2023-2026/Semes...</td>\n",
       "      <td>172</td>\n",
       "      <td>116</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NYU</td>\n",
       "      <td>0010005</td>\n",
       "      <td>/Users/mariaborca/Documents/AI_2023-2026/Semes...</td>\n",
       "      <td>172</td>\n",
       "      <td>116</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  site subject_id                                            tc_path    T  \\\n",
       "0  NYU    0010001  /Users/mariaborca/Documents/AI_2023-2026/Semes...  172   \n",
       "1  NYU    0010002  /Users/mariaborca/Documents/AI_2023-2026/Semes...  172   \n",
       "2  NYU    0010003  /Users/mariaborca/Documents/AI_2023-2026/Semes...  172   \n",
       "3  NYU    0010004  /Users/mariaborca/Documents/AI_2023-2026/Semes...  172   \n",
       "4  NYU    0010005  /Users/mariaborca/Documents/AI_2023-2026/Semes...  172   \n",
       "\n",
       "     R   DX  dx_raw  label  \n",
       "0  116  3.0     3.0      1  \n",
       "1  116  3.0     3.0      1  \n",
       "2  116  0.0     0.0      0  \n",
       "3  116  0.0     0.0      0  \n",
       "4  116  2.0     2.0      1  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df.dropna(subset=[\"label\"]).copy()\n",
    "df_train[\"label\"] = df_train[\"label\"].astype(int)\n",
    "\n",
    "out_path = DATA_PROCESSED / \"subjects_train.csv\"\n",
    "df_train.to_csv(out_path, index=False)\n",
    "\n",
    "print(\"Saved:\", out_path)\n",
    "print(\"Train subjects:\", len(df_train))\n",
    "df_train.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808ed6f0",
   "metadata": {},
   "source": [
    "## Replication site selection\n",
    "\n",
    "To match the experimental setup of the original study, we restrict the dataset\n",
    "to the same acquisition sites used in the paper.\n",
    "\n",
    "**Kept sites:** KKI, NeuroIMAGE, NYU, OHSU, PKU (`Peking_1`)  \n",
    "**Excluded sites:** Pittsburgh, WashU, Brown, Peking_2, Peking_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b0d41a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All sites in df_tc: ['Brown', 'KKI', 'NYU', 'NeuroIMAGE', 'OHSU', 'Peking_1', 'Peking_2', 'Peking_3', 'Pittsburgh', 'WashU']\n",
      "Keeping: ['KKI', 'NYU', 'NeuroIMAGE', 'OHSU', 'Peking_1']\n",
      "Dropping: ['Brown', 'Peking_2', 'Peking_3', 'Pittsburgh', 'WashU']\n"
     ]
    }
   ],
   "source": [
    "SITES_KEEP = {\"KKI\", \"NeuroIMAGE\", \"NYU\", \"OHSU\", \"Peking_1\"}\n",
    "SITES_DROP = {\"WashU\", \"Pittsburgh\", \"Brown\", \"Peking_2\", \"Peking_3\"}\n",
    "\n",
    "print(\"All sites in df_tc:\", sorted(df_tc[\"site\"].unique()))\n",
    "print(\"Keeping:\", sorted(SITES_KEEP))\n",
    "print(\"Dropping:\", sorted(SITES_DROP))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ecf3c3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train subjects (paper sites): 511\n",
      "By site:\n",
      " site\n",
      "NYU           216\n",
      "Peking_1       85\n",
      "KKI            83\n",
      "OHSU           79\n",
      "NeuroIMAGE     48\n",
      "Name: count, dtype: int64\n",
      "\n",
      "By label:\n",
      " label\n",
      "0    285\n",
      "1    226\n",
      "Name: count, dtype: int64\n",
      "\n",
      "By site+label:\n",
      " label        0    1\n",
      "site               \n",
      "KKI         61   22\n",
      "NYU         98  118\n",
      "NeuroIMAGE  23   25\n",
      "OHSU        42   37\n",
      "Peking_1    61   24\n"
     ]
    }
   ],
   "source": [
    "df_train_paper = df_train[df_train[\"site\"].isin(SITES_KEEP)].copy()\n",
    "\n",
    "print(\"Train subjects (paper sites):\", len(df_train_paper))\n",
    "print(\"By site:\\n\", df_train_paper[\"site\"].value_counts())\n",
    "print(\"\\nBy label:\\n\", df_train_paper[\"label\"].value_counts())\n",
    "print(\"\\nBy site+label:\\n\", pd.crosstab(df_train_paper[\"site\"], df_train_paper[\"label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d44593b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /Users/mariaborca/Documents/AI_2023-2026/Semestrul_5/KBS/Report_3/adhd-tcn-replication/data/processed/subjects_train_paper.csv\n"
     ]
    }
   ],
   "source": [
    "out_path = DATA_PROCESSED / \"subjects_train_paper.csv\"\n",
    "df_train_paper.to_csv(out_path, index=False)\n",
    "print(\"Saved:\", out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8433d723",
   "metadata": {},
   "source": [
    "## Dataset summary\n",
    "\n",
    "We report dataset statistics before and after site filtering, including:\n",
    "- number of subjects,\n",
    "- per-site distributions,\n",
    "- class balance.\n",
    "\n",
    "These summaries are used to verify consistency with the dataset reported in the original study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "68db6c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== df_train (all labeled sites) ===\n",
      "n: 709\n",
      "sites: {'NYU': np.int64(216), 'Pittsburgh': np.int64(89), 'Peking_1': np.int64(85), 'KKI': np.int64(83), 'OHSU': np.int64(79), 'Peking_2': np.int64(67), 'NeuroIMAGE': np.int64(48), 'Peking_3': np.int64(42)}\n",
      "labels: {0: np.int64(429), 1: np.int64(280)}\n",
      "\n",
      "=== df_train_paper (paper sites only) ===\n",
      "n: 511\n",
      "sites: {'NYU': np.int64(216), 'Peking_1': np.int64(85), 'KKI': np.int64(83), 'OHSU': np.int64(79), 'NeuroIMAGE': np.int64(48)}\n",
      "labels: {0: np.int64(285), 1: np.int64(226)}\n"
     ]
    }
   ],
   "source": [
    "def summarize(name, df_):\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(\"n:\", len(df_))\n",
    "    print(\"sites:\", dict(df_[\"site\"].value_counts()))\n",
    "    print(\"labels:\", dict(df_[\"label\"].value_counts()))\n",
    "\n",
    "summarize(\"df_train (all labeled sites)\", df_train)\n",
    "summarize(\"df_train_paper (paper sites only)\", df_train_paper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d4fac2",
   "metadata": {},
   "source": [
    "## Notes on replication fidelity\n",
    "\n",
    "- Athena-preprocessed AAL ROI time courses are used directly.\n",
    "- No additional rs-fMRI preprocessing is applied.\n",
    "- Missing values in ROI time series are handled via column-wise mean imputation.\n",
    "- Only one filtered scan per subject is retained.\n",
    "\n",
    "Any deviations from the original study are documented explicitly as part of a\n",
    "partial replication."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4132bf59",
   "metadata": {},
   "source": [
    "## Step 8: Build test subject manifest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3a356236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test phenotypic CSVs: 7\n",
      "  data/raw/phenotypic/Brown/Brown_TestRelease_phenotypic.csv\n",
      "  data/raw/phenotypic/KKI/KKI_TestRelease_phenotypic.csv\n",
      "  data/raw/phenotypic/NYU/NYU_TestRelease_phenotypic.csv\n",
      "  data/raw/phenotypic/NeuroIMAGE/NeuroIMAGE_TestRelease_phenotypic.csv\n",
      "  data/raw/phenotypic/OHSU/OHSU_TestRelease_phenotypic.csv\n",
      "  data/raw/phenotypic/Peking_1/Peking_1_TestRelease_phenotypic.csv\n",
      "  data/raw/phenotypic/Pittsburgh/Pittsburgh_TestRelease_phenotypic.csv\n",
      "Combined test phenotypic rows: 197\n",
      "Example normalized test IDs: ['0026001', '0026002', '0026004', '0026005', '0026009']\n",
      "Test subjects with time courses: 965\n",
      "Missing DX in test (all sites): 768\n",
      "Test subjects (paper sites): 673\n",
      "Missing DX (paper sites): 511\n",
      "Labeled test subjects (paper sites): 0\n",
      "By site:\n",
      " Series([], Name: count, dtype: int64)\n",
      "Saved: /Users/mariaborca/Documents/AI_2023-2026/Semestrul_5/KBS/Report_3/adhd-tcn-replication/data/processed/subjects_test_paper.csv\n",
      "\n",
      "=== Final dataset size (paper-faithful) ===\n",
      "Train subjects: 511\n",
      "Test subjects: 0\n",
      "TOTAL (train + test): 511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3v/16r7246j7hqfn4khg4r1y0k00000gn/T/ipykernel_40628/3102104289.py:48: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_test_paper[\"DX\"] = df_test_paper[\"DX\"].replace({\"withheld\": np.nan, \"Withheld\": np.nan})\n"
     ]
    }
   ],
   "source": [
    "# --- Load TestRelease phenotypic CSVs ---\n",
    "test_pheno_files = sorted([\n",
    "    p for p in PHENO_ROOT.rglob(\"*_TestRelease_phenotypic.csv\")\n",
    "])\n",
    "\n",
    "print(\"Test phenotypic CSVs:\", len(test_pheno_files))\n",
    "for p in test_pheno_files:\n",
    "    print(\" \", p.relative_to(PROJECT_ROOT))\n",
    "\n",
    "dfs_test = []\n",
    "for p in test_pheno_files:\n",
    "    site = p.parent.name\n",
    "    dfp = pd.read_csv(p)\n",
    "    dfp.columns = [c.strip() for c in dfp.columns]\n",
    "    dfp[\"site\"] = site\n",
    "    dfs_test.append(dfp)\n",
    "\n",
    "pheno_test = pd.concat(dfs_test, ignore_index=True)\n",
    "print(\"Combined test phenotypic rows:\", len(pheno_test))\n",
    "\n",
    "\n",
    "# --- Normalize subject IDs (same function as training) ---\n",
    "pheno_test = pheno_test.copy()\n",
    "pheno_test[\"subject_id\"] = pheno_test[\"ScanDir ID\"].apply(norm_subject_id)\n",
    "\n",
    "print(\"Example normalized test IDs:\", pheno_test[\"subject_id\"].dropna().head().tolist())\n",
    "\n",
    "\n",
    "# --- Merge test phenotypes with time-course manifest ---\n",
    "df_test = df_tc.merge(\n",
    "    pheno_test[[\"site\", \"subject_id\", \"DX\"]],\n",
    "    on=[\"site\", \"subject_id\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "print(\"Test subjects with time courses:\", len(df_test))\n",
    "print(\"Missing DX in test (all sites):\", df_test[\"DX\"].isna().sum())\n",
    "\n",
    "\n",
    "# --- Apply paper site filtering ---\n",
    "df_test_paper = df_test[df_test[\"site\"].isin(SITES_KEEP)].copy()\n",
    "\n",
    "print(\"Test subjects (paper sites):\", len(df_test_paper))\n",
    "print(\"Missing DX (paper sites):\", df_test_paper[\"DX\"].isna().sum())\n",
    "\n",
    "\n",
    "# --- Drop unlabeled test subjects (as in the paper) ---\n",
    "df_test_paper[\"DX\"] = df_test_paper[\"DX\"].replace({\"withheld\": np.nan, \"Withheld\": np.nan})\n",
    "\n",
    "df_test_paper_labeled = df_test_paper.dropna(subset=[\"DX\"]).copy()\n",
    "\n",
    "print(\"Labeled test subjects (paper sites):\", len(df_test_paper_labeled))\n",
    "print(\"By site:\\n\", df_test_paper_labeled[\"site\"].value_counts())\n",
    "\n",
    "\n",
    "# --- Save test manifest ---\n",
    "out_path = DATA_PROCESSED / \"subjects_test_paper.csv\"\n",
    "df_test_paper_labeled.to_csv(out_path, index=False)\n",
    "\n",
    "print(\"Saved:\", out_path)\n",
    "\n",
    "\n",
    "# --- Final consistency check: train + test totals ---\n",
    "n_train = len(df_train_paper)\n",
    "n_test = len(df_test_paper_labeled)\n",
    "\n",
    "print(\"\\n=== Final dataset size (paper-faithful) ===\")\n",
    "print(\"Train subjects:\", n_train)\n",
    "print(\"Test subjects:\", n_test)\n",
    "print(\"TOTAL (train + test):\", n_train + n_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a480a1",
   "metadata": {},
   "source": [
    "## Note on Test Set Labels and Evaluation\n",
    "\n",
    "The ADHD-200 dataset was originally released as part of the ADHD-200 Global\n",
    "Competition, in which the data were explicitly divided into a **training set**\n",
    "and a **test set**.\n",
    "\n",
    "For the test set, **diagnostic labels (DX) are intentionally withheld** and\n",
    "provided as the string `\"withheld\"` in the phenotypic files. This design choice\n",
    "prevents label leakage and enables fair benchmarking, but it also means that\n",
    "the official test set **cannot be used for quantitative evaluation** (e.g.,\n",
    "accuracy, AUC) without access to the hidden ground-truth labels.\n",
    "\n",
    "As a result:\n",
    "- The test subject manifest constructed in this notebook is **unlabeled** and\n",
    "  can only be used for **prediction/inference**, not for performance evaluation.\n",
    "- All reported evaluation metrics in this replication study are computed using\n",
    "  labeled subjects from the training set, following the protocol described in\n",
    "  the original paper.\n",
    "- Any additional validation is performed via splits or cross-validation within\n",
    "  the labeled training data.\n",
    "\n",
    "This limitation is inherent to the ADHD-200 dataset and is **not related to the\n",
    "use of Athena-preprocessed data**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cafef5",
   "metadata": {},
   "source": [
    "## Rationale for Training–Validation Split\n",
    "\n",
    "Because diagnostic labels for the official ADHD-200 test release are\n",
    "intentionally withheld, the test set cannot be used for supervised model\n",
    "evaluation. In order to report quantitative performance metrics (e.g.,\n",
    "classification accuracy), a labeled held-out set is required.\n",
    "\n",
    "To address this limitation, we further partition the labeled training data\n",
    "into a **training split** and a **validation split**. This validation split is\n",
    "used exclusively for model selection and performance evaluation, while the\n",
    "training split is used for parameter learning.\n",
    "\n",
    "The split is performed in a stratified manner with respect to the diagnostic\n",
    "label to preserve class balance. A fixed random seed is used to ensure\n",
    "reproducibility. This procedure follows common practice in replication\n",
    "studies when benchmark test labels are unavailable and does not affect the\n",
    "construction of the official test set, which remains reserved for\n",
    "prediction-only analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7f7f3296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved train split: 408\n",
      "Saved val split  : 103\n",
      "Val label counts:\n",
      " label\n",
      "0    57\n",
      "1    46\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_split_source = df_train_paper.copy()\n",
    "\n",
    "train_idx, val_idx = train_test_split(\n",
    "    df_split_source.index,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=df_split_source[\"label\"]\n",
    ")\n",
    "\n",
    "df_train_split = df_split_source.loc[train_idx].copy()\n",
    "df_val_split   = df_split_source.loc[val_idx].copy()\n",
    "\n",
    "df_train_split.to_csv(DATA_PROCESSED / \"subjects_train_split_paper.csv\", index=False)\n",
    "df_val_split.to_csv(DATA_PROCESSED / \"subjects_val_split_paper.csv\", index=False)\n",
    "\n",
    "print(\"Saved train split:\", len(df_train_split))\n",
    "print(\"Saved val split  :\", len(df_val_split))\n",
    "print(\"Val label counts:\\n\", df_val_split[\"label\"].value_counts())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
