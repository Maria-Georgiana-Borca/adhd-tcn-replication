{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2789a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Optional, Union\n",
    "\n",
    "ArrayLike = Union[np.ndarray]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9176436c",
   "metadata": {},
   "source": [
    "## Partition of rs-fMRI time series\n",
    "\n",
    "We follow the paper’s partition strategy: window length L=20 timepoints.\n",
    "To ensure site-consistent window counts, each site is truncated to the\n",
    "time-series length reported in the paper (KKI 119, NYU 171, OHSU 74,\n",
    "NeuroIMAGE 257, Peking_1 231). Subjects shorter than the target length\n",
    "are dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc659b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class WindowingResult:\n",
    "    windows: np.ndarray  # shape: (T, N, L) \n",
    "    T: int               # number of valid windows \n",
    "    dropped: int         # number of dropped timepoints at the end (0...L-1)\n",
    "    L: int               # window length\n",
    "    step: int            # step size between windows\n",
    "    N: int               # number of ROIs\n",
    "    M: int               # original number of timepoints\n",
    "\n",
    "\n",
    "def partition_time_series(\n",
    "    X: ArrayLike,\n",
    "    L: int = 20,\n",
    "    *,\n",
    "    overlap: Optional[int] = None,\n",
    "    step: Optional[int] = None,\n",
    "    time_axis: int = -1,\n",
    "    drop_incomplete: bool = True,\n",
    "    return_metadata: bool = True,\n",
    ") -> Union[np.ndarray, WindowingResult]:\n",
    "    \"\"\"\n",
    "    Sliding-window partitioning of ROI time series.\n",
    "\n",
    "    Params:\n",
    "      - L: window length (timepoints)\n",
    "      - overlap: number of timepoints overlapped between consecutive windows (0..L-1)\n",
    "      - step: hop size between window starts (1..L). If provided, it overrides overlap.\n",
    "      - drop_incomplete: if True, only keep full windows of length L (paper behavior)\n",
    "    \"\"\"\n",
    "    X = np.asarray(X)\n",
    "    if X.ndim != 2:\n",
    "        raise ValueError(f\"X must be 2D, got shape {X.shape}\")\n",
    "    if L <= 0:\n",
    "        raise ValueError(\"L must be positive\")\n",
    "    \n",
    "    if time_axis == 0:\n",
    "        X_nt = X.T\n",
    "    elif time_axis == -1:\n",
    "        X_nt = X\n",
    "    else:\n",
    "        raise ValueError(\"time_axis must be 0 (time first) or -1 (time last)\")\n",
    "    \n",
    "    N, M = X_nt.shape\n",
    "\n",
    "    if step is None:\n",
    "        if overlap is None:\n",
    "            step = L  # no overlap\n",
    "        else:\n",
    "            if not (0 <= overlap < L):\n",
    "                raise ValueError(f\"overlap must be in [0, {L-1}], got {overlap}\")\n",
    "            step = L - overlap\n",
    "    else:\n",
    "        if not (1 <= step <= L):\n",
    "            raise ValueError(f\"step must be in [1, {L}], got {step}\")\n",
    "        \n",
    "    # Compute window start indices\n",
    "    starts = np.arange(0, M, step, dtype=int)\n",
    "    if drop_incomplete:\n",
    "        starts = starts[starts + L <= M]\n",
    "\n",
    "    T = len(starts)\n",
    "    if T == 0:\n",
    "        windows = np.empty((0, N, L), dtype=X.dtype)\n",
    "        dropped = M\n",
    "        return WindowingResult(windows, T, dropped, L, step, N, M) if return_metadata else windows\n",
    "    \n",
    "    windows = np.stack([X_nt[:, s:s+L] for s in starts], axis=0)  # shape (T, N, L)\n",
    "\n",
    "    # Define \"dropped\" as the tail after the last possible full-window start\n",
    "    last_start = starts[-1]\n",
    "    used_until = last_start + L\n",
    "    dropped = max(0, M - used_until)\n",
    "\n",
    "    if return_metadata:\n",
    "        return WindowingResult(windows, T, dropped, L, step, N, M)\n",
    "    else:\n",
    "        return windows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65dd770a",
   "metadata": {},
   "source": [
    "## What this notebook outputs\n",
    "\n",
    "This notebook converts each subject’s ROI time series into non-overlapping windows\n",
    "of shape `(T, 116, 20)` and stores them for reproducible model training.\n",
    "\n",
    "**Outputs:**\n",
    "- Window tensors:\n",
    "  - `data/processed/windows/train/<SITE>/<SUBJECT_ID>.npy`\n",
    "  - `data/processed/windows/val/<SITE>/<SUBJECT_ID>.npy`\n",
    "- A manifest mapping each subject to its saved window file:\n",
    "  - `data/processed/windows_manifest.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "870cbc8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train rows: 408 | cols: ['site', 'subject_id', 'tc_path', 'T', 'R', 'DX', 'dx_raw', 'label']\n",
      "Val rows  : 103 | cols: ['site', 'subject_id', 'tc_path', 'T', 'R', 'DX', 'dx_raw', 'label']\n",
      "Inferred PATH_COL: tc_path\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 1) Config\n",
    "# =========================\n",
    "EXPECTED_N = 116\n",
    "L = 20\n",
    "STEP = 20\n",
    "DROP_IF_SHORTER = True\n",
    "DTYPE = np.float32\n",
    "PROGRESS_EVERY = 50\n",
    "\n",
    "PAPER_M = {\n",
    "    \"KKI\": 119,\n",
    "    \"NYU\": 171,\n",
    "    \"OHSU\": 74,\n",
    "    \"NeuroIMAGE\": 257,\n",
    "    \"Peking_1\": 231,\n",
    "}\n",
    "\n",
    "CANDIDATE_PATH_COLS = [\n",
    "    \"tc_path\", \"timeseries_path\", \"time_series_path\", \"path\",\n",
    "    \"roi_ts_path\", \"roi_timeseries_path\", \"file\", \"filepath\",\n",
    "    \"roi_path\", \"aal_path\"\n",
    "]\n",
    "\n",
    "# =========================\n",
    "# 2) Paths + load manifests\n",
    "# =========================\n",
    "PROJECT_ROOT = Path(\"..\").resolve()\n",
    "DATA_PROCESSED = PROJECT_ROOT / \"data\" / \"processed\"\n",
    "\n",
    "TRAIN_CSV = DATA_PROCESSED / \"subjects_train_split_paper.csv\"\n",
    "VAL_CSV   = DATA_PROCESSED / \"subjects_val_split_paper.csv\"\n",
    "\n",
    "OUT_ROOT = DATA_PROCESSED / \"windows\"\n",
    "OUT_TRAIN = OUT_ROOT / \"train\"\n",
    "OUT_VAL   = OUT_ROOT / \"val\"\n",
    "OUT_TRAIN.mkdir(parents=True, exist_ok=True)\n",
    "OUT_VAL.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df_train = pd.read_csv(TRAIN_CSV)\n",
    "df_val   = pd.read_csv(VAL_CSV)\n",
    "\n",
    "print(f\"Train rows: {len(df_train)} | cols: {list(df_train.columns)}\")\n",
    "print(f\"Val rows  : {len(df_val)} | cols: {list(df_val.columns)}\")\n",
    "\n",
    "def infer_path_col(df: pd.DataFrame) -> str:\n",
    "    cols = {c.lower(): c for c in df.columns}\n",
    "    for cand in CANDIDATE_PATH_COLS:\n",
    "        if cand.lower() in cols:\n",
    "            return cols[cand.lower()]\n",
    "    for c in df.columns:\n",
    "        if \"path\" in c.lower():\n",
    "            return c\n",
    "    raise ValueError(\"Could not infer a time-series path column (expected something like tc_path).\")\n",
    "\n",
    "PATH_COL = infer_path_col(df_train)\n",
    "if PATH_COL not in df_val.columns:\n",
    "    raise ValueError(f\"PATH_COL='{PATH_COL}' not found in val CSV columns.\")\n",
    "print(\"Inferred PATH_COL:\", PATH_COL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c05bbdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 3) Time series loading + shape utilities\n",
    "# =========================\n",
    "def load_subject_timeseries(tc_path: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Load Athena AAL ROI time series from .1D (or other simple formats).\n",
    "    Returns a 2D array, typically (T, N) from CSV parsing; we fix orientation later.\n",
    "    \"\"\"\n",
    "    p = Path(tc_path)\n",
    "    if not p.is_absolute():\n",
    "        p = (PROJECT_ROOT / p).resolve()\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(f\"Time-series file not found: {p}\")\n",
    "\n",
    "    suf = p.suffix.lower()\n",
    "    if suf == \".npy\":\n",
    "        return np.asarray(np.load(p))\n",
    "    if suf == \".npz\":\n",
    "        z = np.load(p)\n",
    "        return np.asarray(z[list(z.keys())[0]])\n",
    "\n",
    "    if suf == \".csv\":\n",
    "        df = pd.read_csv(p, sep=\",\")\n",
    "    elif suf == \".tsv\":\n",
    "        df = pd.read_csv(p, sep=\"\\t\")\n",
    "    elif suf in [\".txt\", \".1d\"]:\n",
    "        df = pd.read_csv(p, sep=r\"\\s+|\\t+\", engine=\"python\", comment=\"#\")\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file extension: {suf} for {p}\")\n",
    "\n",
    "    if df.shape[1] == 1:\n",
    "        df = pd.read_csv(p, sep=r\"\\s+\", engine=\"python\", comment=\"#\")\n",
    "\n",
    "    mean_cols = [c for c in df.columns if str(c).startswith(\"Mean_\")]\n",
    "    if mean_cols:\n",
    "        roi_df = df[mean_cols]\n",
    "    else:\n",
    "        drop_cols = [c for c in df.columns if str(c).lower() in [\"file\", \"sub-brick\", \"subbrick\", \"brick\", \"index\"]]\n",
    "        roi_df = df.drop(columns=drop_cols, errors=\"ignore\").apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "    roi_df = roi_df.dropna(axis=0, how=\"all\")\n",
    "    X = roi_df.to_numpy(dtype=float)\n",
    "\n",
    "    if X.ndim != 2:\n",
    "        raise ValueError(f\"Loaded time series must be 2D, got shape {X.shape} from {p}\")\n",
    "    return X\n",
    "\n",
    "def ensure_N_by_M(X: np.ndarray, expected_N: int = EXPECTED_N) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Ensure output is (N, M).\n",
    "    Accepts X in (N, M) or (M, N) and returns (N, M).\n",
    "    \"\"\"\n",
    "    if X.shape[0] == expected_N:\n",
    "        return X\n",
    "    if X.shape[1] == expected_N:\n",
    "        return X.T\n",
    "    raise ValueError(f\"Expected one dim == N={expected_N}, got shape {X.shape}\")\n",
    "\n",
    "def truncate_to_paper_length(X_nm: np.ndarray, site: str, *, drop_if_shorter: bool = DROP_IF_SHORTER) -> Optional[np.ndarray]:\n",
    "    target = PAPER_M.get(site)\n",
    "    if target is None:\n",
    "        return X_nm\n",
    "    M = X_nm.shape[1]\n",
    "    if M >= target:\n",
    "        return X_nm[:, :target]\n",
    "    return None if drop_if_shorter else X_nm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53b82d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] processed 50/408 | saved 50\n",
      "[train] processed 100/408 | saved 100\n",
      "[train] processed 150/408 | saved 150\n",
      "[train] processed 200/408 | saved 200\n",
      "[train] processed 250/408 | saved 249\n",
      "[train] processed 300/408 | saved 299\n",
      "[train] processed 350/408 | saved 349\n",
      "[train] processed 400/408 | saved 399\n",
      "[train] dropped_shorter_than_paper: 1 / 408\n",
      "[val] processed 50/103 | saved 50\n",
      "[val] processed 100/103 | saved 100\n",
      "[val] dropped_shorter_than_paper: 0 / 103\n",
      "Saved: /Users/mariaborca/Documents/AI_2023-2026/Semestrul_5/KBS/Report_3/adhd-tcn-replication/data/processed/windows_manifest.csv\n",
      "Train windows saved: 407\n",
      "Val windows saved  : 103\n",
      "Output root: /Users/mariaborca/Documents/AI_2023-2026/Semestrul_5/KBS/Report_3/adhd-tcn-replication/data/processed/windows\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 4) Window + save\n",
    "# =========================\n",
    "def build_and_save_windows(df: pd.DataFrame, split: str) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    n = len(df)\n",
    "    dropped_short = 0\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        site = row[\"site\"]\n",
    "        subj = row[\"subject_id\"]\n",
    "\n",
    "        try:\n",
    "            label = int(row[\"label\"])\n",
    "\n",
    "            X = load_subject_timeseries(row[PATH_COL])\n",
    "            X_nm = ensure_N_by_M(X, expected_N=EXPECTED_N)\n",
    "            X_nm = truncate_to_paper_length(X_nm, site, drop_if_shorter=DROP_IF_SHORTER)\n",
    "            if X_nm is None:\n",
    "                dropped_short += 1\n",
    "                continue\n",
    "\n",
    "            res = partition_time_series(\n",
    "                X_nm,\n",
    "                L=L,\n",
    "                step=STEP,\n",
    "                time_axis=-1,\n",
    "                drop_incomplete=True,\n",
    "                return_metadata=True,\n",
    "            )\n",
    "            windows = res.windows.astype(DTYPE, copy=False)  # (T, N, L)\n",
    "            if not (windows.shape[1] == EXPECTED_N and windows.shape[2] == L):\n",
    "                raise ValueError(f\"Unexpected windows shape: {windows.shape}\")\n",
    "\n",
    "            out_dir = OUT_ROOT / split / site\n",
    "            out_dir.mkdir(parents=True, exist_ok=True)\n",
    "            out_path = out_dir / f\"{subj}.npy\"\n",
    "            np.save(out_path, windows)\n",
    "\n",
    "            rows.append({\n",
    "                \"split\": split,\n",
    "                \"site\": site,\n",
    "                \"subject_id\": subj,\n",
    "                \"label\": label,\n",
    "                \"T\": int(windows.shape[0]),\n",
    "                \"N\": int(windows.shape[1]),\n",
    "                \"L\": int(windows.shape[2]),\n",
    "                \"M_used\": int(res.M),\n",
    "                \"dropped_tail\": int(res.dropped),\n",
    "                \"windows_path\": str(out_path.relative_to(PROJECT_ROOT)),\n",
    "            })\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] {split} | {site} | {subj} | {e}\")\n",
    "            continue\n",
    "\n",
    "        if (i + 1) % PROGRESS_EVERY == 0:\n",
    "            print(f\"[{split}] processed {i+1}/{n} | saved {len(rows)}\")\n",
    "\n",
    "    print(f\"[{split}] dropped_shorter_than_paper: {dropped_short} / {n}\")\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# =========================\n",
    "# 5) Run + save manifest\n",
    "# =========================\n",
    "windows_train = build_and_save_windows(df_train, \"train\")\n",
    "windows_val   = build_and_save_windows(df_val, \"val\")\n",
    "\n",
    "windows_manifest = pd.concat([windows_train, windows_val], ignore_index=True)\n",
    "\n",
    "OUT_MANIFEST = DATA_PROCESSED / \"windows_manifest.csv\"\n",
    "windows_manifest.to_csv(OUT_MANIFEST, index=False)\n",
    "\n",
    "print(\"Saved:\", OUT_MANIFEST)\n",
    "print(\"Train windows saved:\", len(windows_train))\n",
    "print(\"Val windows saved  :\", len(windows_val))\n",
    "print(\"Output root:\", OUT_ROOT)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
